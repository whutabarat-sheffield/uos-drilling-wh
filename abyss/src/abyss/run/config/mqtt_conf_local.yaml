# MQTT Configuration for Drilling Data Analysis System
# ================================================

# This configuration file defines the MQTT broker connection settings and topic structures
# for the drilling data analysis system. The system listens for two types of messages:
# - Result messages: Contains metadata and results
# - Trace messages: Contains detailed trace data

# Topic Structure Examples:
# - Results: OPCPUBSUB/toolboxid/toolid/ResultManagement
# - Traces: OPCPUBSUB/toolboxid/toolid/ResultManagement/Trace

# Where:
# - OPCPUBSUB: Root topic prefix
# - toolboxid: ID of the toolbox (e.g., ILLL502033771)
# - toolid: ID of the specific tool (e.g., setitectest)

mqtt:
  # Broker Connection Settings
  # ------------------------
  # These settings define the connection details for the MQTT broker
  broker:
    # Host can be one of:
    # - "localhost" for local development
    # - "host.docker.internal" for Docker containers to connect to host machine
    # - Actual hostname or IP for production
    # TODO: Update the host based on the actual broker location
    # host: "mqtt-broker"  # Use "host.docker.internal" for Docker or "mqtt-broker" for service name in Docker Compose
    # host: "host.docker.internal"
    host: localhost
    # host: "192.168.1.97"  # Example IP address, replace with actual broker IP if needed
    
    # Standard MQTT port (default: 1883)
    # TODO: Update the port if the broker uses a different port
    port: 1883
    
    # Authentication credentials (if required by broker)
    username: ""  # Optional: Set username for authenticated connections
    password: ""  # Optional: Set password for authenticated connections

  # Listener Configuration
  # --------------------
  # These settings define the topic structure to listen for messages
  # and the data field mappings to extract specific data from the payload
  # TODO: Update these paths based on the actual data structure
  listener:
    # Behaviour in case of duplicate messages
    duplicate_handling: "ignore"  # Options: "ignore", "replace", "error"
    # Topic Structure
    # --------------
    # TODO: Update the root, toolboxid, and toolid based on the actual topic structure
    root: "OPCPUBSUB"  # Root topic prefix
    
    # Tool identification patterns:
    # "+" = wildcard to match any single level
    # Specific ID = listen only to that specific tool
    toolboxid: "+"  # Use specific ID (e.g., "ILLL502033771") or "+" for all
    toolid: "+"     # Use specific ID (e.g., "setitectest") or "+" for all
    
    # Message type suffixes
    result: "ResultManagement"        # Suffix for result messages
    trace: "ResultManagement/Trace"   # Suffix for trace messages
    heads: "AssetManagement/Heads"

  # Data Field Mappings
  # -----------------
  # These paths define where to find specific data fields in the message payload
  # TODO: Update these paths based on the actual data structure
  data_ids:
    # Machine identification
    machine_id: 'ResultManagement.Results.0.ResultMetaData.SerialNumber'
    head_id: 'AssetManagement.Assets.Heads.0.Identification.SerialNumber'
    result_id: 'ResultManagement.Results.0.ResultMetaData.ResultId'
    trace_result_id: 'ResultManagement.Results.0.ResultContent.Trace.StepTraces.PositionTrace.StepResultId'
    
    # Trace data paths
    position: 'ResultManagement.Results.0.ResultContent.Trace.StepTraces.PositionTrace.StepTraceContent[0].Values'
    thrust:   'ResultManagement.Results.0.ResultContent.Trace.StepTraces.IntensityThrustTrace.StepTraceContent[0].Values'
    torque:   'ResultManagement.Results.0.ResultContent.Trace.StepTraces.IntensityTorqueTrace.StepTraceContent[0].Values'
    step:     'ResultManagement.Results.0.ResultContent.Trace.StepTraces.StepNumberTrace.StepTraceContent[0].Values'
    
    # Empty value references
    torque_empty_vals: 'ResultManagement.Results.0.ResultContent.StepResults.0.StepResultValues.IntensityTorqueEmpty'
    thrust_empty_vals: 'ResultManagement.Results.0.ResultContent.StepResults.0.StepResultValues.IntensityThrustEmpty'
    step_vals: 'ResultManagement.Results.0.ResultContent.StepResults.0.StepResultValues.StepNumber'

  # Estimation Configuration
  # ----------------------
  # These paths define where to publish or store the results of the algorithm
  # TODO: Update these paths based on the actual data structure
  estimation:
    keypoints: 'ResultManagement.Results.0.ResultContent.DepthEstimation.KeyPoints'
    depth_estimation: 'ResultManagement.Results.0.ResultContent.DepthEstimation.DepthEstimation'

  # Processing Configuration
  # -----------------------
  # Settings for parallel message processing using ProcessPoolExecutor
  processing:
    # Number of worker processes for parallel depth inference
    # Each worker loads its own DepthInference model (~1GB memory each)
    # Recommended: 10 workers for 100 msg/sec with 0.5s processing time
    workers: 10
    
    # Model ID to use for depth inference
    model_id: 4

  # Depth Validation Configuration
  # -----------------------------
  # Controls how the system handles edge cases in depth estimation
  depth_validation:
    # How to handle negative depth values
    # Options:
    #   - "publish": Always publish, even with negative values (default)
    #   - "skip": Don't publish when negative values are detected
    #   - "warning": Publish but log warnings
    negative_depth_behavior: "publish"
    
    # Track sequential negative depths for operational insights
    track_sequential_negatives: true
    
    # Alert threshold - warn after this many sequential negatives
    sequential_threshold: 5
    
    # Time window for sequential tracking (in minutes)
    sequential_window_minutes: 5

  # Test Publisher Configuration -- For Testing Only
  # -------------------------
  publisher:
    topics:
      # Example topics using specific tool IDs
      result: "OPCPUBSUB/ILLL502033771/setitectest/ResultManagement"
      trace: "OPCPUBSUB/ILLL502033771/setitectest/ResultManagement/Traces"
    client_id: "setitec_publisher"  # Unique ID for the test publisher